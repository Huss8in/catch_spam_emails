{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJqMkVxmqGwi"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/content/emails.csv')"
      ],
      "metadata": {
        "id": "VjMCv6A-qSvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('emails').getOrCreate()\n",
        "df = spark.read.csv('emails.csv', header=True, inferSchema=True)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "lMgdZ2EWqtIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.DataFrame(df.take(5), columns=df.columns).transpose()"
      ],
      "metadata": {
        "id": "-yUzz1bgqtKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "oQRupic4x3Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
        "stages=[]\n",
        "numericCols = ['the','to','for','a','you','hou','is','this','i','your','we','are','com','please','price','attached','th','forward','u','click','unsubscribe','pro','therefore','cc','prize','hi','deadline','ur']\n",
        "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
        "stages += [assembler]"
      ],
      "metadata": {
        "id": "D6URwQ26qtM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages = stages)\n",
        "pipelineModel = pipeline.fit(df)\n",
        "df = pipelineModel.transform(df)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "5dHPKpKHq_uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "print(\"Test Dataset Count: \" + str(test.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Af4nt-rBJB",
        "outputId": "1fb1bcc7-459e-4c87-f515-f2c559ea4f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 3663\n",
            "Test Dataset Count: 1509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.ml.classification.MultilayerPerceptronClassifier.html"
      ],
      "metadata": {
        "id": "kJ_sMDdVumZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "mlp = MultilayerPerceptronClassifier(featuresCol = 'features', labelCol = 'Spam', layers = [ 28, 14, 4, 2 ])\n",
        "mlpModel = mlp.fit(train)\n",
        "predictions = mlpModel.transform(test)\n",
        "predictions"
      ],
      "metadata": {
        "id": "gIr9aEeerCzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/spark-multilayer-perceptron-classifier-for-poi-classification-99e5c68b4a77"
      ],
      "metadata": {
        "id": "NvjNpKkK3VQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = mlpModel.transform(test)\n",
        "result.show(10)"
      ],
      "metadata": {
        "id": "NdFvupX23MA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol = 'Spam', predictionCol = 'prediction', metricName = 'accuracy')\n",
        "mlpacc = evaluator.evaluate(result)\n",
        "mlpacc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkT7EpA5rC35",
        "outputId": "3837271e-88cd-4abd-8447-e11889bf52d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8502319416832339"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
        "categoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
        "stages = []\n",
        "for categoricalCol in categoricalColumns:\n",
        "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
        "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
        "    stages += [stringIndexer, encoder]\n",
        "label_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\n",
        "stages += [label_stringIdx]\n",
        "numericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n",
        "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "stages += [assembler]"
      ],
      "metadata": {
        "id": "wMUHCV3D7iNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}